# 朴素贝叶斯分类器

标签（空格分隔）： 机器学习

---



# 核心
``贝叶斯决策理论的核心思想：选择高概率对应的类别，选择具有最高概率的决策。``
```
p(ci|x,y) = p(x,y|ci)p(ci)/p(x,y)
```
贝叶斯分类准则：

如果p(c1|x,y) > p(c2|x,y),则属于类别c1；
如果p(c1|x,y) < p(c2|x,y),则属于类别c2；

给定由（x,y)表示的数据点，那么该数据点属于类别c1的概率是多少？属于类别c2的概率是多少？

#优缺点
`优点`：在数据较少的情况下依然有效，可以处理多类别问题
`缺点`：对于输入数据的准备方式较为敏感
`适用数据类型`：标称型数据(离散值，监督学习中的分类)

# 使用
在任意分类场景中都可以使用，常用于文档分类

# 朴素含义
“朴素”基于两个假设：
>1. 属性条件独立性假设,指的是统计意义上的独立，即一个特征或者单词出现的可能性与它和其他单词相邻没有关系。是真正的朴素的含义。
如果这个条件进行一定程度的放松，就是“半朴素贝叶斯分类器”。
2. 朴素贝叶斯分类器中的另一个假设是，每个特征同等重要.

# 计算时注意
可能遇到的问题，会对最终的结果产生不好的影响

1. 比如：在文档分类任务中，在计算时 p(w0|c1)p(w1|c1)...p(wn|c1) ,要计算多个概率的乘积以获得某个文档属于某个类别概率，可能其中有一个是0，结果就是0了

这种情况：**因训练集样本不充分而导致概率估值为0**。

> **如何避免这种影响？**
（即避免其他属性携带的信息被训练集中未出现的属性值“抹去”）
在估计概率值时进行平滑，常用“拉普拉斯修正”。

在文档分类中，可以将所有词的出现次数都初始化为1，并将分母初始化为2（分母是总词数，既然训练了，那么一定是有两类，每个类至少一个词语了，那么总词数至少为2了，初始化为2，这个括号的理解是没有看机器学习西瓜书之前自己理解的。看了西瓜书之后，发现这就是拉普拉斯修正方法，2代表的就是训练集可能的类别数目局）


2. 太多很小的数相乘容易造成`下溢出`，以得不到正确答案，
解决：对乘积取自然对数。

用自然对数进行处理好处：
1. 避免下溢出或浮点数舍入导致出错
2. 没有任何损失，函数f(x)和 ln(f(x))函数曲线在相同区域内同时增加或减少，在同一个点取得极值。



# 算法
1. 数据的收集 ：提供文本文件
2. 数据的准备：数值型或布尔型
3. 分析数据
4. 训练算法：计算不同的独立特征的条件概率，（“计数”）
5. 测试算法：计算错误率
6. 使用算法：以实际应用为驱动