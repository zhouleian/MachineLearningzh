# 机器学习：集成学习笔记


标签（空格分隔）： 机器学习

---

# 一、应用背景

在机器学习的很多领域都应用到了集成学习，如分类问题集成，回归问题集成，特征选取集成，异常点检测集成等等，是机器学习中一个非常重要且热门的分支。但它不是机器学习中的一种学习算法，也不是一种分类器，而是将多个分类器结合的方法，这些分类器可以是同种，也可以是不同种分类器，可以是决策树，神经网络，贝叶斯分类器，K-近邻等。

将多个分类器结合体现了集成学习的简单思想：“博采众长”，“三个臭皮匠赛过诸葛亮”。并且已经有学者理论上证明了集成学习的思想是可以提高分类器的性能的，比如说统计上的原因，计算上的原因以及表示上的原因等。 

实现集成学习的方法很多，后文不对集成学习性能的提高做研究，重点讨论集成学习的一般结构，各个分类器如何得到，如何训练，如何结合等。

# 二、集成学习基本概念
集成学习的提出是为了“提高学习性能”，所以，个体学习器为“弱学习器”的时候，这种提升尤为明显。这里的“弱学习器”指的是泛化性能略优于随意瞎猜的学习器，例如，在而分类中分类的正确率略高于50%的分类器被称为弱学习器。所以，在研究集成学习的算法时，一般是针对弱学习器进行的，但在实际实践中，出于某些考虑：比如希望使用更少学习器等，往往会使用较强的学习器。 

下面首先通过集成学习的示意图，逐步介绍集成学习方法的构成和使用。
![集成学习示意图][1]
集成学习即：先产生一组个体学习器，再用某种结合方法将个体学习器结合起来，得到输出。所以，集成学习的重点有两个：1. 选择个体学习器； 2. 将个体学习器结合的策略。

## 2.1 个体学习器
个体学习器可以是同种类型的，这样的集成称为“同质”，也可以是不同类型的，称为“异质”。

### 2.1.1 同质集成学习
所有的个体学习器都是同一个种类,由同一个算法生成。比如“决策树集成”中都是决策树个体学习器，或者“神经网络集成”中全是神经网络个体学习器等。此时个体学习器通常又被称作基学习器（base learner），相应的学习算法称为“基学习算法”。
一般说的集成学习指的是，同质集成学习。

### 2.1.2 异质集成学习
所有的个体学习器不全是一个种类的。例如，在机器学习任务中，同时对训练数据集使用决策树和神经网络，再通过某种结合策略来确定最终的强学习器。不同个体学习器由不同学习算法生成，不再有“基学习算法”，此时个体学习器又被称作组件学习器（component learner）。

# 三、集成学习的核心


对学习器的结合输出，我们采用“投票法”产生。在下面的假设下：
假设：所有学习器误差相互独立，
当T足够大的时候，集成的错误率指数级下降，并趋向于0。

但是，由于所有的学习器是为解决一个问题提出的，所以显然不可能相互独立！所以，集成学习的一个目标即“好而不同”，好是指个体学习器的准确性尽可能的高，显然如果大家每个个体学习器的准确率都高的话，“集成“之后的效果一定也不会差；不同是指不同个体学习器之间的多样性，尽量能够互相弥补彼此的不足。

所以，**产生并结合“好而不同”的学习器，就是集成学习研究的核心。**

集成学习的关键：
 1. 如产生每个分类器？分类器训练算法？
 2. 如何结合各个学习器得到强分类器？

了解了集成学习的关键，下面介绍实现的集成学习方法。

# 四、 集成学习方法

集成学习方法按照个体学习器之间是否存在依赖关系可以分为两类：
1. 第一个是个体学习器之间存在强依赖关系，必须串行执生成的序列化方法：代表算法是boosting算法；
2. 第二个是个体学习器之间不存在强依赖关系，可同时生成的并行化方法，代表算法是bagging和随机森林（Random Forest）算法。

下面就分别介绍这两类算法。

# 五、 Boosting
另一篇博客

# 六、 Bagging
另一篇博客


  [1]: http://omxy7x542.bkt.clouddn.com/17-12-16/50261498.jpg
  